/*************************************************************************
 * Copyright (C) [2022] by Cambricon, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *************************************************************************/
#include "three_interpolate.h"

#include "core/logging.h"
#include "kernels/debug.h"
#include "kernels/kernel.h"
#include "kernels/utils/common.h"

__nram__ int8_t nram_buffer[MAX_NRAM_SIZE];
#define MIN(x, y) ((x) < (y) ? (x) : (y))
#define BATCH_LIMIT 1
#define INDEX_WEIGHT_LAST_DIM 3
#define INT32_MAX_MASK 0xffffffff
#define INT16_MAX_MASK 0xffff
#define INT32_MASK_REPEAT_TIMES 4
#define INT16_MASK_REPEAT_TIMES 2
#define INT32_MAX_NUM 2147483647
#define INT2FLOAT_KEEP_PRECISION_MAX_VALUE 16777216

template <typename T>
__mlu_func__ void memcpy2D(T *dst, const T *src, uint32_t data_size,
                           mluMemcpyDirection_t dir, uint64_t dst_stride,
                           uint64_t src_stride, uint32_t segnum) {
  for (uint32_t loopi = 0; loopi <= segnum; ++loopi) {
    int8_t *dst_addr = (int8_t *)dst + loopi * dst_stride * sizeof(T);
    int8_t *src_addr = (int8_t *)src + loopi * src_stride * sizeof(T);
    __memcpy(dst_addr, src_addr, data_size * sizeof(T), dir);
  }
}

template <typename T>
__mlu_func__ void selectIndicesBetweenMinAndMaxWithoutLimit(
    int32_t *nram_indices, int32_t *nram_indices_transpose,
    int32_t *nram_indices_transpose_addition,
    int32_t *nram_indices_transpose_float,
    int32_t *nram_indices_transpose_float_addition, T *nram_weights_transpose,
    const uint32_t m_min, const uint32_t m_max, const uint32_t index,
    const uint32_t n_limit, const uint32_t c_limit,
    const uint32_t m_limit_org) {
  // select the offset between the m_min and m_max
  // judge if less than m_max
  __bang_ge_scalar((int32_t *)nram_indices_transpose_float_addition,
                   nram_indices_transpose + index * n_limit, m_max, n_limit);
  __bang_not((int32_t *)nram_indices_transpose_float_addition,
             (int32_t *)nram_indices_transpose_float_addition, n_limit);
  // judge if greater or equal than m_min
  __bang_ge_scalar((int32_t *)nram_indices_transpose_addition,
                   nram_indices_transpose + index * n_limit, m_min, n_limit);
  // get the bool values in the range of [m_min, m_max)
  __bang_and((int32_t *)nram_indices_transpose_addition,
             (int32_t *)nram_indices_transpose_float_addition,
             (int32_t *)nram_indices_transpose_addition, n_limit);
  // extra process for the nan/inf
  // set weights to be 0 for the indices not in range of [m_min, m_max)
  if (sizeof(T) == sizeof(float)) {
    int32_t *nram_mask_int32 = (int32_t *)nram_indices_transpose_float_addition;
    __bang_mul_scalar((int32_t *)nram_mask_int32,
                      (int32_t *)nram_indices_transpose_addition,
                      (int32_t)INT32_MAX_MASK, n_limit);
    __bang_band((int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)nram_mask_int32, INT32_MASK_REPEAT_TIMES * n_limit);
  } else if (sizeof(T) == sizeof(half)) {
    int16_t *nram_mask_int16 = (int16_t *)nram_indices_transpose_float_addition;
    __bang_int322int16(nram_mask_int16,
                       (int32_t *)nram_indices_transpose_addition, n_limit, 0,
                       0);
    __bang_mul_scalar((int16_t *)nram_mask_int16, (int16_t *)nram_mask_int16,
                      (int16_t)INT16_MAX_MASK, n_limit);
    __bang_band((int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)nram_mask_int16, INT16_MASK_REPEAT_TIMES * n_limit);
  }
  // multiply the indices with values in the range of [m_min, m_max)
  __bang_mul((int32_t *)nram_indices_transpose_float,
             nram_indices_transpose + index * n_limit,
             (int32_t *)nram_indices_transpose_addition, n_limit);
  // get the bool values not in the range of [m_min, m_max)
  __bang_not((int32_t *)nram_indices_transpose_float_addition,
             (int32_t *)nram_indices_transpose_addition, n_limit);
  // multiply the values not in the range of [m_min, m_max) with
  // m_limit_org + m_min
  __bang_mul_scalar((int32_t *)nram_indices_transpose_float_addition,
                    (int32_t *)nram_indices_transpose_float_addition,
                    m_limit_org + m_min, n_limit);
  // add the indices in range of [m_min, m_max) with the special
  // indices(same as
  // m_limit_org + m_min) not in range of [m_min, m_max)
  __bang_add((int32_t *)nram_indices_transpose_float,
             (int32_t *)nram_indices_transpose_float,
             (int32_t *)nram_indices_transpose_float_addition, n_limit);
  // get the relative indices by subtract m_min
  __bang_sub_scalar((int32_t *)nram_indices_transpose_float,
                    (int32_t *)nram_indices_transpose_float, m_min, n_limit);
  // get the beginning offset by multiply c_limit
  __bang_mul_scalar(nram_indices, (int32_t *)nram_indices_transpose_float,
                    c_limit, n_limit);
}

template <typename T>
__mlu_func__ void selectIndicesBetweenMinAndMax(
    int32_t *nram_indices, int32_t *nram_indices_transpose,
    float *nram_indices_transpose_addition, float *nram_indices_transpose_float,
    float *nram_indices_transpose_float_addition, T *nram_weights_transpose,
    const uint32_t m_min, const uint32_t m_max, const uint32_t index,
    const uint32_t n_limit, const uint32_t c_limit,
    const uint32_t m_limit_org) {
  __bang_int322float(nram_indices_transpose_float,
                     nram_indices_transpose + index * n_limit, n_limit, 0);
  // select the offset between the m_min and m_max
  // judge if less than m_max
  __bang_ge_scalar(nram_indices_transpose_float_addition,
                   nram_indices_transpose_float, m_max, n_limit);
  __bang_not(nram_indices_transpose_float_addition,
             nram_indices_transpose_float_addition, n_limit);
  // judge if greater or equal than m_min
  __bang_ge_scalar(nram_indices_transpose_addition,
                   nram_indices_transpose_float, m_min, n_limit);
  // get the bool values in the range of [m_min, m_max)
  __bang_and(nram_indices_transpose_addition,
             nram_indices_transpose_float_addition,
             nram_indices_transpose_addition, n_limit);
  // extra process for the nan/inf
  // set weights to be 0 for the indices not in range of [m_min, m_max)
  if (sizeof(T) == sizeof(float)) {
    int32_t *nram_mask_int32 = (int32_t *)nram_indices_transpose_float_addition;
    __bang_float2int32(nram_mask_int32, nram_indices_transpose_addition,
                       n_limit, 0);
    __bang_mul_scalar((int32_t *)nram_mask_int32, (int32_t *)nram_mask_int32,
                      (int32_t)INT32_MAX_MASK, n_limit);
    __bang_band((int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)nram_mask_int32, INT32_MASK_REPEAT_TIMES * n_limit);
  } else if (sizeof(T) == sizeof(half)) {
    int16_t *nram_mask_int16 = (int16_t *)nram_indices_transpose_float_addition;
    __bang_float2int16_rd(nram_mask_int16, nram_indices_transpose_addition,
                          n_limit, 0);
    __bang_mul_scalar((int16_t *)nram_mask_int16, (int16_t *)nram_mask_int16,
                      (int16_t)INT16_MAX_MASK, n_limit);
    __bang_band((int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)(nram_weights_transpose + index * n_limit),
                (int8_t *)nram_mask_int16, INT16_MASK_REPEAT_TIMES * n_limit);
  }
  // multiply the indices with values in the range of [m_min, m_max)
  __bang_mul(nram_indices_transpose_float, nram_indices_transpose_float,
             nram_indices_transpose_addition, n_limit);
  // get the bool values not in the range of [m_min, m_max)
  __bang_not(nram_indices_transpose_float_addition,
             nram_indices_transpose_addition, n_limit);
  // multiply the values not in the range of [m_min, m_max) with
  // m_limit_org + m_min
  __bang_mul_scalar(nram_indices_transpose_float_addition,
                    nram_indices_transpose_float_addition, m_limit_org + m_min,
                    n_limit);
  // add the indices in range of [m_min, m_max) with the special
  // indices(same as
  // m_limit_org + m_min) not in range of [m_min, m_max)
  __bang_add(nram_indices_transpose_float, nram_indices_transpose_float,
             nram_indices_transpose_float_addition, n_limit);
  // get the relative indices by subtract m_min
  __bang_sub_scalar(nram_indices_transpose_float, nram_indices_transpose_float,
                    m_min, n_limit);
  // get the beginning offset by multiply c_limit
  __bang_mul_scalar(nram_indices_transpose_float, nram_indices_transpose_float,
                    c_limit, n_limit);
  __bang_float2int32(nram_indices, nram_indices_transpose_float, n_limit, 0);
}

template <typename T>
__mlu_global__ void MLUKernelThreeInterpolateForward(
    const T *features, const int *__restrict__ indices, const T *weights,
    const uint32_t b, const uint32_t c, const uint32_t m, const uint32_t n,
    const uint32_t c_limit_size, const uint32_t m_limit_size,
    const uint32_t n_limit_size, T *output) {
  if (__is_mpu()) {
    return;
  }
  uint32_t align_base_128 = NFU_ALIGN_SIZE / sizeof(T);
  uint32_t c_limit = c_limit_size;
  uint32_t m_limit = m_limit_size;
  uint32_t n_limit = n_limit_size;

  uint32_t c_aligned_limit = CEIL_ALIGN(c, c_limit);
  uint32_t m_aligned_limit = CEIL_ALIGN(m, m_limit);
  uint32_t n_aligned_limit = CEIL_ALIGN(n, n_limit);

  c_limit = c_limit > c_aligned_limit ? c_aligned_limit : c_limit;
  m_limit = m_limit > m_aligned_limit ? m_aligned_limit : m_limit;
  n_limit = n_limit > n_aligned_limit ? n_aligned_limit : n_limit;
  uint32_t c_limit_org = c_limit;
  uint32_t m_limit_org = m_limit;
  uint32_t n_limit_org = n_limit;

  uint32_t c_repeated_times = c_aligned_limit / c_limit;
  uint32_t m_repeated_times = m_aligned_limit / m_limit;

  uint32_t batch_n_repeated_times =
      (b * n_aligned_limit) / (BATCH_LIMIT * n_limit);
  uint32_t batch_n_per_core = batch_n_repeated_times / taskDim;
  uint32_t batch_n_remain = batch_n_repeated_times % taskDim;

  batch_n_per_core += (taskId < batch_n_remain);

  uint32_t features_deal_size = c_limit * m_limit;
  uint32_t indices_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  uint32_t weights_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  uint32_t output_deal_size = c_limit * n_limit;
  uint32_t reuse_deal_size = features_deal_size >= output_deal_size
                                 ? features_deal_size
                                 : output_deal_size;

  /*
   * NRAM partition
   *  |-----------------------------------------------------------------------------------|
   *  |           nram_features                  | nram_features_transpose |
   *  |-----------------------------------------------------------------------------------|
   *  |           nram_features_selected         | nram_output         |
   *  |-----------------------------------------------------------------------------------|
   *  |      nram_weights         |   nram_weights_transpose  | nram_indices |
   *  |-----------------------------------------------------------------------------------|
   *  | nram_indices_transpose(addition/float/float_addition) |
   *  |-----------------------------------------------------------------------------------|
   */

  T *nram_features = (T *)nram_buffer;  // MAX(c_limit*m_limit, c_limit*n_limit)
  T *nram_features_transpose =
      (T *)nram_features + reuse_deal_size;  // m_limit*c_limit
  T *nram_features_selected =
      (T *)nram_features_transpose + features_deal_size;  // n_limit*c_limit
  T *nram_output =
      (T *)nram_features_selected + output_deal_size;     // c_limit*n_limit
  T *nram_weights = (T *)nram_output + output_deal_size;  // n_limit*3
  T *nram_weights_transpose =
      (T *)nram_weights + weights_deal_size;  // n_limit*3
  int32_t *nram_indices =
      (int32_t *)(nram_weights_transpose + weights_deal_size);  // n_limit*3
  int32_t *nram_indices_transpose =
      (int32_t *)nram_indices + indices_deal_size;  // n_limit*3
  float *nram_indices_transpose_addition =
      (float *)(nram_indices_transpose + indices_deal_size);  // n_limit
  float *nram_indices_transpose_float =
      (float *)(nram_indices_transpose_addition + n_limit);  // n_limit
  float *nram_indices_transpose_float_addition =
      (float *)(nram_indices_transpose_float + n_limit);  // n_limit

  for (uint32_t i = 0; i < batch_n_per_core; ++i) {
    n_limit = n_limit_org;
    uint32_t current_batch_n = i + taskId * batch_n_per_core;
    current_batch_n += (taskId >= batch_n_remain ? batch_n_remain : 0);
    uint32_t current_batch = current_batch_n * n_limit / n_aligned_limit;
    uint32_t current_n = current_batch_n % (n_aligned_limit / n_limit);

    uint32_t real_indices_deal_size = indices_deal_size;
    uint32_t actual_n_size = n_limit;

    uint32_t n_segment = n_aligned_limit / n_limit;
    uint32_t n_remain = n % n_limit;
    if (n_remain == 0) {
      n_remain = n_limit;
    }
    uint32_t remains = current_batch_n / n_segment;
    uint32_t segments = current_batch_n - remains;

    int32_t *base_addr_indices =
        (int32_t *)indices +
        (segments * n_limit + remains * n_remain) * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_weights =
        (T *)weights +
        (segments * n_limit + remains * n_remain) * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_features = (T *)features + current_batch * c * m;
    T *base_addr_output =
        (T *)output + current_batch * c * n + current_n * n_limit;

    uint32_t n_mod_limit = n % n_limit;
    if (current_n == (n_aligned_limit / n_limit - 1) && (n_mod_limit != 0)) {
      real_indices_deal_size = n_mod_limit * INDEX_WEIGHT_LAST_DIM;
      actual_n_size = n_mod_limit;
      n_limit = MIN(CEIL_ALIGN(n_mod_limit, align_base_128), n_limit);
    }
    // 1. Load
    // 1.1 load indices and weights
    __memcpy(nram_indices, base_addr_indices,
             real_indices_deal_size * sizeof(int32_t), GDRAM2NRAM);
    __memcpy(nram_weights, base_addr_weights,
             real_indices_deal_size * sizeof(T), GDRAM2NRAM);
    // transpose the indices and weights
    for (uint32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
      __bang_write_value(nram_indices_transpose + index * n_limit, n_limit, -1);
      __bang_write_zero(nram_weights_transpose + index * n_limit, n_limit);
      __memcpy(nram_indices_transpose + index * n_limit, nram_indices + index,
               sizeof(int32_t), NRAM2NRAM, sizeof(int32_t),
               INDEX_WEIGHT_LAST_DIM * sizeof(int32_t), actual_n_size - 1);
      __memcpy(nram_weights_transpose + index * n_limit, nram_weights + index,
               sizeof(T), NRAM2NRAM, sizeof(T),
               INDEX_WEIGHT_LAST_DIM * sizeof(T), actual_n_size - 1);
    }
    // extra process for the nan/inf
    // backup the weights after transpose
    __memcpy(nram_weights, nram_weights_transpose,
             weights_deal_size * sizeof(T), NRAM2NRAM);

    uint32_t c_rem = c;
    for (uint32_t j = 0; j < c_repeated_times; ++j) {
      uint32_t c_slice = c_limit < c_rem ? c_limit : c_rem;
      c_rem -= c_slice;
      uint32_t c_limit_new = c_limit;
      if (c_slice != c_limit && c_slice % c_limit != 0) {
        c_limit_new =
            MIN(CEIL_ALIGN(c_slice % c_limit, align_base_128), c_limit_new);
      }
      // 1.2 load Co*Mo features data
      __bang_write_zero(nram_output, output_deal_size);
      uint32_t m_rem = m;
      for (uint32_t k = 0; k < m_repeated_times; ++k) {
        uint32_t m_slice = m_limit < m_rem ? m_limit : m_rem;
        m_rem -= m_slice;
        uint32_t m_limit_new = m_limit;
        if (m_slice != m_limit && m_slice % m_limit != 0) {
          m_limit_new =
              MIN(CEIL_ALIGN(m_slice % m_limit, align_base_128), m_limit_new);
        }
        uint32_t dst_stride = m_limit_new * sizeof(T);
        uint64_t src_stride = m * sizeof(T);
        if (src_stride <= INT32_MAX_NUM) {
          __memcpy(nram_features,
                   base_addr_features + (j * m * c_limit + k * m_limit),
                   m_slice * sizeof(T), GDRAM2NRAM, dst_stride, src_stride,
                   c_slice - 1);
        } else {
          // src_stride in __memcpy is int type, here handles src_stride
          // overflow int32 max
          memcpy2D(nram_features,
                   base_addr_features + (j * m * c_limit + k * m_limit),
                   m_slice, GDRAM2NRAM, m_limit_new, m, c_slice - 1);
        }
        // 2. Compute
        __bang_write_zero(nram_features_transpose,
                          features_deal_size + c_limit);
        c_limit = c_limit_new;
        m_limit = m_limit_new;
        // 2.1 transpose features from Co*Mo to Mo*Co to easily select one whole
        // channel data
        __bang_transpose(nram_features_transpose, nram_features, c_limit,
                         m_limit);
        uint32_t m_min = k * m_limit_org;
        uint32_t m_max = m_min + m_slice;
        for (uint32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
          __bang_write_zero(nram_features, output_deal_size);
          __bang_write_zero(nram_features_selected, output_deal_size);
          // 2.2 select the offset between the m_min and m_max
          // convert indices from int32_t to float
          if (m <= INT2FLOAT_KEEP_PRECISION_MAX_VALUE) {
            // float compute force is bigger than int
            selectIndicesBetweenMinAndMax(
                nram_indices, nram_indices_transpose,
                nram_indices_transpose_addition, nram_indices_transpose_float,
                nram_indices_transpose_float_addition, nram_weights_transpose,
                m_min, m_max, index, n_limit, c_limit, m_limit_org);
          } else {
            selectIndicesBetweenMinAndMaxWithoutLimit(
                nram_indices, nram_indices_transpose,
                (int32_t *)nram_indices_transpose_addition,
                (int32_t *)nram_indices_transpose_float,
                (int32_t *)nram_indices_transpose_float_addition,
                nram_weights_transpose, m_min, m_max, index, n_limit, c_limit,
                m_limit_org);
          }
          // select the features from m*c to n*c
          // 2.3 select the Mo*Co according to the indices
          for (uint32_t s = 0; s < actual_n_size; ++s) {
            // select the features
            uint32_t selected_index = nram_indices[s];
            __memcpy(nram_features + s * c_limit,
                     nram_features_transpose + selected_index,
                     c_limit * sizeof(T), NRAM2NRAM);
          }  // n_repeated_times
          // 2.4 transpose from No*Co to Co*No to easily do the mul with No
          __bang_transpose(nram_features_selected, nram_features, n_limit,
                           c_limit);
          // 2.5 mul the features and weightss
          __bang_cycle_mul(nram_features_selected, nram_features_selected,
                           nram_weights_transpose + index * n_limit,
                           c_limit * n_limit, n_limit);
          // 2.6 add the different index's results
          __bang_add(nram_output, nram_features_selected, nram_output,
                     c_limit * n_limit);
          // extra process for the nan/inf
          // restore the nram_weights_transpose from nram_weights
          __memcpy(nram_weights_transpose + index * n_limit,
                   nram_weights + index * n_limit, n_limit * sizeof(T),
                   NRAM2NRAM);
        }  // index
        c_limit = c_limit_org;
        m_limit = m_limit_org;
      }  // m_repeated_time
      // 3. Store Co*No data
      __memcpy(base_addr_output + (j * n * c_limit), nram_output,
               actual_n_size * sizeof(T), NRAM2GDRAM, n * sizeof(T),
               n_limit * sizeof(T), c_slice - 1);
    }  // c_repeated_times
  }    // batch_n_per_core
}

template <typename T>
__mlu_global__ void MLUKernelThreeInterpolateBackward(
    const T *grad_output, const int *__restrict__ indices, const T *weights,
    const uint32_t b, const uint32_t c, const uint32_t m, const uint32_t n,
    const uint32_t c_limit_size, const uint32_t m_limit_size,
    const uint32_t n_limit_size, T *grad_features) {
  if (__is_mpu()) {
    return;
  }
  uint32_t align_base_128 = NFU_ALIGN_SIZE / sizeof(T);
  uint32_t c_limit = c_limit_size;
  uint32_t m_limit = m_limit_size;
  uint32_t n_limit = n_limit_size;

  uint32_t c_aligned_limit = CEIL_ALIGN(c, c_limit);
  uint32_t m_aligned_limit = CEIL_ALIGN(m, m_limit);
  uint32_t n_aligned_limit = CEIL_ALIGN(n, n_limit);

  c_limit = c_limit > c_aligned_limit ? c_aligned_limit : c_limit;
  m_limit = m_limit > m_aligned_limit ? m_aligned_limit : m_limit;
  n_limit = n_limit > n_aligned_limit ? n_aligned_limit : n_limit;
  uint32_t c_limit_org = c_limit;
  uint32_t m_limit_org = m_limit;
  uint32_t n_limit_org = n_limit;

  uint32_t c_repeated_times = c_aligned_limit / c_limit;
  uint32_t n_repeated_times = n_aligned_limit / n_limit;

  uint32_t batch_m_repeated_times =
      (b * m_aligned_limit) / (BATCH_LIMIT * m_limit);
  uint32_t batch_m_per_core = batch_m_repeated_times / taskDim;
  uint32_t batch_m_remain = batch_m_repeated_times % taskDim;

  batch_m_per_core += (taskId < batch_m_remain);

  uint32_t grad_output_deal_size = c_limit * n_limit;
  uint32_t indices_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  uint32_t weights_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  uint32_t grad_features_deal_size = c_limit * m_limit;
  uint32_t reuse_deal_size = grad_output_deal_size >= grad_features_deal_size
                                 ? grad_output_deal_size
                                 : grad_features_deal_size;

  /*
   * NRAM partition
   *  |-------------------------------------------------------------------------------------------|
   *  |           nram_grad_output                  | nram_grad_output_transpose
   * |
   *  |-------------------------------------------------------------------------------------------|
   *  |           nram_grad_features                |
   * nram_grad_features_transpose         |
   *  |-------------------------------------------------------------------------------------------|
   *  |      nram_weights            |   nram_weights_transpose     |
   * nram_indices           |
   *  |-------------------------------------------------------------------------------------------|
   *  |      nram_indices_transpose(addition/float/float_addition)  |
   *  |-------------------------------------------------------------------------------------------|
   */

  T *nram_grad_output = (T *)nram_buffer;  // c_limit*n_limit
  T *nram_grad_output_transpose =
      (T *)nram_grad_output +
      grad_output_deal_size;  // n_limit*c_limit + c_limit
  T *nram_grad_features = (T *)nram_grad_output_transpose +
                          grad_output_deal_size + c_limit;  // m_limit*c_limit
  T *nram_grad_features_transpose =
      (T *)nram_grad_features +
      grad_features_deal_size;  // max(c_limit*m_limit, c_limit*n_limit)
  T *nram_weights =
      (T *)nram_grad_features_transpose + reuse_deal_size;  // n_limit*3
  T *nram_weights_transpose =
      (T *)nram_weights + weights_deal_size;  // n_limit*3
  int32_t *nram_indices =
      (int32_t *)(nram_weights_transpose + weights_deal_size);  // n_limit*3
  int32_t *nram_indices_transpose =
      (int32_t *)nram_indices + indices_deal_size;  // n_limit*3
  float *nram_indices_transpose_addition =
      (float *)(nram_indices_transpose + indices_deal_size);  // n_limit
  float *nram_indices_transpose_float =
      (float *)(nram_indices_transpose_addition + n_limit);  // n_limit
  float *nram_indices_transpose_float_addition =
      (float *)(nram_indices_transpose_float + n_limit);  // n_limit

  for (uint32_t i = 0; i < batch_m_per_core; ++i) {
    m_limit = m_limit_org;
    uint32_t current_batch_m = i + taskId * batch_m_per_core;
    current_batch_m += (taskId >= batch_m_remain ? batch_m_remain : 0);
    uint32_t current_batch = current_batch_m * m_limit / m_aligned_limit;
    uint32_t current_m = current_batch_m % (m_aligned_limit / m_limit);
    uint32_t real_indices_deal_size = indices_deal_size;
    uint32_t actual_m_size = m_limit;

    int32_t *base_addr_indices =
        (int32_t *)indices + current_batch * n * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_weights =
        (T *)weights + current_batch * n * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_grad_output = (T *)grad_output + current_batch * c * n;
    T *base_addr_grad_features = (T *)grad_features +
                                 /*different batch*/ current_batch * c * m +
                                 /*different m*/ current_m * m_limit;

    uint32_t m_mod_limit = m % m_limit;
    if (current_m == (m_aligned_limit / m_limit - 1) && (m_mod_limit != 0)) {
      actual_m_size = m_mod_limit;
      m_limit = MIN(CEIL_ALIGN(m_mod_limit, align_base_128), m_limit);
    }

    uint32_t m_min = current_m * m_limit_org;
    uint32_t m_max = m_min + actual_m_size;

    uint32_t c_rem = c;
    for (uint32_t j = 0; j < c_repeated_times; ++j) {
      uint32_t c_slice = c_limit < c_rem ? c_limit : c_rem;
      c_rem -= c_slice;
      uint32_t c_limit_new = c_limit;
      if (c_slice != c_limit && c_slice % c_limit != 0) {
        c_limit_new =
            MIN(CEIL_ALIGN(c_slice % c_limit, align_base_128), c_limit_new);
      }
      // initial the nram_grad_features with 0
      __bang_write_zero(nram_grad_features, grad_features_deal_size);
      uint32_t n_rem = n;
      for (uint32_t k = 0; k < n_repeated_times; ++k) {
        uint32_t n_slice = n_limit < n_rem ? n_limit : n_rem;
        n_rem -= n_slice;
        uint32_t n_limit_new = n_limit;
        if (n_slice != n_limit && n_slice % n_limit != 0) {
          n_limit_new =
              MIN(CEIL_ALIGN(n_slice % n_limit, align_base_128), n_limit_new);
        }
        real_indices_deal_size = n_slice * INDEX_WEIGHT_LAST_DIM;
        // load weights and indices
        __memcpy(nram_indices,
                 base_addr_indices + k * n_limit * INDEX_WEIGHT_LAST_DIM,
                 real_indices_deal_size * sizeof(int32_t), GDRAM2NRAM);
        __memcpy(nram_weights,
                 base_addr_weights + k * n_limit * INDEX_WEIGHT_LAST_DIM,
                 real_indices_deal_size * sizeof(T), GDRAM2NRAM);
        // load grad_output
        uint32_t dst_stride = n_limit_new * sizeof(T);
        uint64_t src_stride = n * sizeof(T);
        if (src_stride <= INT32_MAX_NUM) {
          __memcpy(nram_grad_output,
                   base_addr_grad_output + (j * n * c_limit + k * n_limit),
                   n_slice * sizeof(T), GDRAM2NRAM, dst_stride, src_stride,
                   c_slice - 1);
        } else {
          // src_stride in __memcpy is int type, here handles src_stride
          // overflow int32 max
          memcpy2D(nram_grad_output,
                   base_addr_grad_output + (j * n * c_limit + k * n_limit),
                   n_slice, GDRAM2NRAM, n_limit_new, n, c_slice - 1);
        }
        // transpose the indices and weights
        for (uint32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
          __bang_write_value(nram_indices_transpose + index * n_limit, n_limit,
                             -1);
          __bang_write_zero(nram_weights_transpose + index * n_limit, n_limit);
          __memcpy(nram_indices_transpose + index * n_limit_new,
                   nram_indices + index, sizeof(int32_t), NRAM2NRAM,
                   sizeof(int32_t), INDEX_WEIGHT_LAST_DIM * sizeof(int32_t),
                   n_slice - 1);
          __memcpy(nram_weights_transpose + index * n_limit_new,
                   nram_weights + index, sizeof(T), NRAM2NRAM, sizeof(T),
                   INDEX_WEIGHT_LAST_DIM * sizeof(T), n_slice - 1);
        }
        // extra process for the nan/inf
        // backup the weights after transpose
        __memcpy(nram_weights, nram_weights_transpose,
                 weights_deal_size * sizeof(T), NRAM2NRAM);
        // initial nram_grad_output_transpose with zero
        // and set extra c_limit size that will be selected by the index not in
        // [m_min, m_max)
        __bang_write_zero(nram_grad_output_transpose,
                          grad_output_deal_size + c_limit);
        c_limit = c_limit_new;
        n_limit = n_limit_new;
        for (uint32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
          // select the offset between the m_min and m_max
          // convert indices from int32_t to float
          if (m <= INT2FLOAT_KEEP_PRECISION_MAX_VALUE) {
            // float compute force is bigger than int
            selectIndicesBetweenMinAndMax(
                nram_indices, nram_indices_transpose,
                nram_indices_transpose_addition, nram_indices_transpose_float,
                nram_indices_transpose_float_addition, nram_weights_transpose,
                m_min, m_max, index, n_limit, c_limit, m_limit_org);
          } else {
            selectIndicesBetweenMinAndMaxWithoutLimit(
                nram_indices, nram_indices_transpose,
                (int32_t *)nram_indices_transpose_addition,
                (int32_t *)nram_indices_transpose_float,
                (int32_t *)nram_indices_transpose_float_addition,
                nram_weights_transpose, m_min, m_max, index, n_limit, c_limit,
                m_limit_org);
          }
          // mul the grad_output and weights
          __bang_cycle_mul(nram_grad_features_transpose, nram_grad_output,
                           nram_weights_transpose + index * n_limit,
                           c_limit * n_limit, n_limit);
          __bang_transpose(nram_grad_output_transpose,
                           nram_grad_features_transpose, c_limit, n_limit);
          // add the mul results to the grad_features selected
          // by the index
          for (uint32_t s = 0; s < n_slice; ++s) {
            uint32_t selected_index = nram_indices[s];
            __bang_add(nram_grad_features + selected_index,
                       nram_grad_features + selected_index,
                       nram_grad_output_transpose + s * c_limit, c_limit);
          }
          // extra process for the nan/inf
          // restore the nram_weights_transpose from nram_weights
          __memcpy(nram_weights_transpose + index * n_limit,
                   nram_weights + index * n_limit, n_limit * sizeof(T),
                   NRAM2NRAM);
        }  // index
        c_limit = c_limit_org;
        n_limit = n_limit_org;
      }  // n_repeated_times
      // transpose the results from Mo*Co to Co*Mo
      __bang_transpose(nram_grad_features_transpose, nram_grad_features,
                       m_limit, c_limit_new);
      // store Co*Mo data
      __memcpy(base_addr_grad_features + (j * m * c_limit),
               nram_grad_features_transpose, actual_m_size * sizeof(T),
               NRAM2GDRAM, m * sizeof(T), m_limit * sizeof(T), c_slice - 1);
    }  // c_repeated_times
  }    // batch_m_per_core
}

mluOpStatus_t MLUOP_WIN_API KernelThreeInterpolateForward(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    mluOpDataType_t d_type, const void *features, const void *indices,
    const void *weights, const uint32_t b, const uint32_t c, const uint32_t m,
    const uint32_t n, const uint32_t c_limit_size, const uint32_t m_limit_size,
    const uint32_t n_limit_size, void *output) {
  switch (d_type) {
    /* Only float and half data types are supported
       in host-side CPP file fool-proof processing. */
    case MLUOP_DTYPE_FLOAT: {
      KERNEL_CHECK(MLUKernelThreeInterpolateForward<<<k_dim, k_type, queue>>>(
          (float *)features, (int *)indices, (float *)weights, b, c, m, n,
          c_limit_size, m_limit_size, n_limit_size, (float *)output));
    }; break;
    case MLUOP_DTYPE_HALF: {
      KERNEL_CHECK(MLUKernelThreeInterpolateForward<<<k_dim, k_type, queue>>>(
          (half *)features, (int *)indices, (half *)weights, b, c, m, n,
          c_limit_size, m_limit_size, n_limit_size, (half *)output));
    }; break;
    default:
      break;
  }
  return MLUOP_STATUS_SUCCESS;
}

mluOpStatus_t MLUOP_WIN_API KernelThreeInterpolateBackward(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    mluOpDataType_t d_type, const void *grad_output, const void *indices,
    const void *weights, const uint32_t b, const uint32_t c, const uint32_t m,
    const uint32_t n, const uint32_t c_limit_size, const uint32_t m_limit_size,
    const uint32_t n_limit_size, void *grad_features) {
  switch (d_type) {
    /* Only float and half data types are supported
       in host-side CPP file fool-proof processing. */
    case MLUOP_DTYPE_FLOAT: {
      KERNEL_CHECK(MLUKernelThreeInterpolateBackward<<<k_dim, k_type, queue>>>(
          (float *)grad_output, (int *)indices, (float *)weights, b, c, m, n,
          c_limit_size, m_limit_size, n_limit_size, (float *)grad_features));
    }; break;
    case MLUOP_DTYPE_HALF: {
      KERNEL_CHECK(MLUKernelThreeInterpolateBackward<<<k_dim, k_type, queue>>>(
          (half *)grad_output, (int *)indices, (half *)weights, b, c, m, n,
          c_limit_size, m_limit_size, n_limit_size, (half *)grad_features));
    }; break;
    default:
      break;
  }
  return MLUOP_STATUS_SUCCESS;
}
