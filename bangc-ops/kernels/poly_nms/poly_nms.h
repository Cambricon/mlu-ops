/*************************************************************************
* Copyright (C) [2019-2022] by Cambricon, Inc.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
* OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
* IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
* CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
* TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
* SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
*************************************************************************/

#ifndef BANGC_OPS_KERNELS_POLY_NMS_POLY_NMS_H
#define BANGC_OPS_KERNELS_POLY_NMS_POLY_NMS_H

#include "core/mlu_op_core.h"
#include "core/runtime/device.h"

#include "kernels/poly_nms/enums.h"

#define MASK_T_BITWIDTH 32 // mask will be stored in an uint32_t value


template<int MIN_BOX_NUM_PER_CORE>
struct _BlockConfig{
  _BlockConfig(mluOpHandle_t handle, int box_num, int core_num_limit = 0) {
    int core_num_to_use = mluop::runtime::getJobLimitCapability(handle);
    if (core_num_limit > 0) {
      core_num_to_use = std::min(core_num_limit, core_num_to_use);
    }
    core_num_to_use = std::min(core_num_to_use, (box_num + MIN_BOX_NUM_PER_CORE - 1) / MIN_BOX_NUM_PER_CORE);
    dim.x = core_num_to_use;
    dim.y = 1;
    dim.z = 1;
  }
  cnrtFunctionType_t kernel_type = cnrtFunctionType_t::cnrtFuncTypeBlock;
  cnrtDim3_t dim;
};

/**
 * Generate launch config for MLUCalcArea. By default, we will launch as many BLOCKs as we can.
 */
struct MLUCalcAreaLaunchConfig: public _BlockConfig<128> {
  using _BlockConfig::_BlockConfig;
};

/**
 * A block kernel that convert an [N,9] array of input_boxes into [N,1] array of boxes_area
 * @param input_boxes device pointer to boxes
 * @param input_boxes_num the value of N
 * @param real_width the stride on dim 0 (the row may have padded, if no padding, it should be 9)
 * @param boxes_area[out] device pointer to boxes_area
 */
__mlu_global__ void MLUCalcArea(const float *__restrict__ input_boxes,
                                int input_boxes_num,
                                int real_width,
                                float *__restrict__ boxes_area);

/**
 * Generate launch config for MLUCalcArea. By default, we will launch as many BLOCKs as we can.
 */
struct MLUGenNMSMaskLaunchConfig: public _BlockConfig<8> {
  using _BlockConfig::_BlockConfig;
};

/**
 * A kernel to generate mask and sort_info, see genResult Kernel to get how mask and sort_info are used.
 *
 * Given that input_boxes is a [N,9] array, boxes_area a [N,1] array
 * The `mask` will be a [N,N] matrix, with initial value of 0, if mask[i,j] == 1,
 * it means ith box is allowed to suppress jth box, but whether the suppression will happen is decided by genResult Kernel
 *
 * Note that, to reduce the memory usage, the row of `mask` will be stored as bit in a uint32_t container.
 *
 * The sort_info is an [N,1] int array, given k = sort_info[i] , it means the kth box is the ith largest score box,
 * e.g. if sort_info[0] == 22 , then, the 22th box will be the box with the highest score
 *
 * @param input_boxes device pointer to boxes
 * @param input_boxes_num the value of N
 * @param real_width the stride on dim 0 (the row may have padded, if no padding, it should be 9)
 * @param threshold the IOU threshold
 * @param boxes_area device pointer to boxes' area
 * @param mask[out] device pointer to mask
 * @param sort_info[out] device pointer to sort info
 * @return
 */
__mlu_global__ void MLUGenNMSMask(const float *__restrict__ input_boxes,
                                  int input_boxes_num,
                                  int real_width,
                                  float threshold,
                                  const float *__restrict__ boxes_area,
                                  uint32_t *mask,
                                  int *sort_info);

/**
 * Gen result by reduce the masks generated by MLUGenNMSMask
 *
 * @tparam OUTPUT_ORDER which output order to use
 *
 * @param input_boxes_num the value of N
 * @param p_mask device pointer to mask
 * @param p_sort_info device pointer to sort info
 * @param o_index device pointer to output indexes
 * @param o_num device pointer to output number
 * @return
 */
template<OutputOrder OUTPUT_ORDER>
__mlu_global__ void MLUGenNMSResult(int input_boxes_num,
                                    const uint32_t *__restrict__ p_mask,
                                    const int *__restrict__ p_sort_info,
                                    int *o_index,
                                    int *o_num);


extern template
__mlu_global__ void MLUGenNMSResult<OutputOrder::HIGH_SCORE_FIRST>(int input_boxes_num,
                                    const uint32_t *__restrict__ p_mask,
                                    const int *__restrict__ p_sort_info,
                                    int *o_index,
                                    int *o_num);

extern template
__mlu_global__ void MLUGenNMSResult<OutputOrder::LOW_BOX_ID_FIRST>(int input_boxes_num,
                                    const uint32_t *__restrict__ p_mask,
                                    const int *__restrict__ p_sort_info,
                                    int *o_index,
                                    int *o_num);

/**
 * A util function to get the working set of current core, every core will handle boxes in range of
 * [*o_begin, *o_begin + *o_box_num)
 *
 * @param input_boxes_num[in] the total box number
 * @param o_box_num[out] the number of boxes current core should processed
 * @param o_beg [out] the beginning box id of current core
 */
__mlu_func__ static inline void GetCoreWorkingSet(int input_boxes_num, int *o_box_num, int *o_beg) {
  int core_box_num = input_boxes_num / taskDim;
  int rem = input_boxes_num % taskDim;
  int box_i_beg = 0;
  if (taskId < rem) {
    core_box_num += taskId < rem;
    box_i_beg = core_box_num * taskId;
  } else {
    box_i_beg = core_box_num * taskId + rem;
  }
  *o_box_num = core_box_num;
  *o_beg = box_i_beg;
}

#endif //BANGC_OPS_KERNELS_POLY_NMS_POLY_NMS_H
