# LU分解实现方案

## 1.LU分解原理

LU分解将原矩阵A分解为一个下三角矩阵L（Lower triangular matrix）和一个上三角矩阵U（Upper triangular matrix）的乘积,其中下三角矩阵L的元素为：为了消去![img](1.png)这个位置所乘乘数的相反数。上三角U矩阵的元素为对原矩阵进行高斯消去后的结果。

![image-20240524110329017](2.png)

一个选主元的串行LU分解算法的步骤如下：

![image-20240524110539395](3.png)

在LU分解的串行计算是按照颜色顺序依次计算的，比如要计算L中的元素![img](4.png),需要减去左侧元素和上方元素之和然后除以对角线元素![img](5.png)：![img](6.png),在计算U中的元素![img](5.png)时同样需要减去其左侧元素和其上方元素：![img](7.png)，可以看出L和U矩阵中每个元素的计算依赖于左侧和上方的元素，导致数据必须按照依赖关系进行。

所以对于同一列的值可以用向量矩阵乘批量计算，为了计算元素![img](8.png)需要减去的减数可以这么计算：![img](9.png)，且![img](10.png)

![img](11.png) 

而对同行不同列的元素进行计算时，![img](12.png)之间存在相同的元素，如果此时在合并计算![img](13.png)时，需要注意他们之间还存在依赖。通过分块将串行计算转化为矩阵乘法，此时应该需要注意块外的依赖和块内的依赖，

## 2.实现方案设计

LU分解共分为三个过程，分别代表了在不同层次和分块尺寸上对矩阵进行分解。

首先看最外层的过程(按照图示箭头方向循环执行)：

![img](15.png) 

该过程中输入的矩阵规模为(m,n)，主要是将输入的矩阵分解成大小为nb的列条块，分块的尺寸根据输入矩阵的规模决定，范围大致在128-512之间，将宽度为nb大小的列条块输入到下一级递归分解算法sgetrf_recpanel中去，蓝色表示当前正在处理的部分，绿色表示进行当前运算的输入，也代表已经完成的部分。



过程2 :sgetrf_recpanel输入的矩阵为过程1中输入的宽度为nb的列条块，先将输入的矩阵再次分为大小相同的两部分A1和A2，直到A1的宽度小于预设的阈值recpnb为止，这里的recpnb大小为32。先对A1执行最底层的分解sgetf2_native，

![img](16.png) 

完成后对A2进行更新：通过矩阵求逆运算trsm将结果矩阵写在(0,n1)位置，

![img](17.png) 

然后通过矩阵乘运算gemm更新(n1,n1)处的矩阵，最后再对A2进行最底层的分解sgetf2_native。

![img](18.png) 

过程3 sgetf2_native中输入的矩阵为过程2中输入的宽度为recpnb的列条块，这是最底层的分解算法。它先将输入的矩阵继续分解为nb大小的小列条块，这里的nb取值为8，然后对每一个小列条块的每一列进行循环：找出当前第i列的最大元、进行行交换、计算当前主元右侧的子矩阵元素。

![img](19.png)

完成后对下一个小列条块进行更新：通过矩阵求逆运算trsm将结果矩阵写在(j,j+nb)位置，然后通过矩阵乘运算gemm更新(j+nb,j+nb)处的矩阵。

 

![img](20.png) 

## 4.MLU层需求分析

### 4.1.算子需求分析

| 算子功能简介                                                 | LU分解              |
| ------------------------------------------------------------ | ------------------- |
| 需求来源                                                     | pytorch             |
| 应用网络                                                     |                     |
| 输入数据类型                                                 | float/complex float |
| 输入shape                                                    | [batch,M,N]         |
| 输入layout                                                   | array               |
| 输出数据类型                                                 | float/complex float |
| 输出shape                                                    | [batch,M,N]         |
| 输出layout                                                   | array               |
| 模式                                                         | pivot/no pivot      |
| 是否含有 dim/axis 等类似语义的参数且该参数支持负数/其他特殊处理 | 否                  |
| 是否含有 labels/index 等类似语义的参数且该参数支持负数/界外情况/其他特殊处理 | 否                  |
| 是否需要支持原位                                             | 是                  |
| 是否需要支持stride机制                                       | 是                  |
| 是否需要支持广播                                             | 否                  |
| 0元素检查是否直接返回                                        | 否                  |
| 其他特殊需求                                                 | 无                  |
| 本次开发优先支持的规模/模式                                  |                     |

### 4.2.LU分解算子功能和应用场景描述

LU 分解的功能是将原始矩阵 A 分解为两个矩阵 L 和 U，满足 A = LU。其中，L 是一个下三角矩阵，其对角线元素为 1，上三角元素全为 0，而 U 是一个上三角矩阵，其下三角元素全为 0。通过 LU 分解，我们可以将原始线性方程组 Ax = b 转化为 LUx = b，进而可以通过回代求解步骤求解出 x。

### 4.3.算子输入输出参数要求

| 参数        | 语义               | 类型      | 支持类型             | 物理布局 | 规模限制         |
| ----------- | ------------------ | --------- | -------------------- | -------- | ---------------- |
| handle      |                    | 句柄      |                      |          |                  |
| Input_desc  | 矩阵描述符         | 输入      |                      |          |                  |
| Input       | 输入矩阵           | 输入/输出 | float、complex float | array    | shape[batch,M,N] |
| output_desc | 矩阵描述符         | 输入      |                      |          |                  |
| output      | 输入矩阵           | 输入/输出 | float、complex float | array    | shape[batch,M,N] |
| mode        | 模式pivot/no pivot | 输入      | bool                 |          |                  |

### 4.4. **算子接口设计**

mluOpStatus_t mluOp_WIN_API mluOpLUFactorization(mluOpHandle_t handle, const mluOpTensorDescriptor_t input_desc, void *input,const mluOpTensorDescriptor_t output_desc, void *output,const bool mode);
