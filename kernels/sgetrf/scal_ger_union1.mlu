#include "sgetrf.h"

#include "core/logging.h"
#include "kernels/debug.h"
#include "kernels/kernel.h"

#define N 4
#define MAX_M_SIZE 16384
#define CEILDIV(x,y) ( (x + y - 1)/y)


__mlu_entry__ void MLUKernelScal_ger(
    int m, int n, int step,
    float *dA, int lda,
    int *info, int gbstep)
    {
        int tx  = taskIdX;
        // int gtx = taskId;
        // checkinfo to avoid computation of the singular matrix
        if( (*info) != 0 ) return;
        // printf("tx %d and gtx %d  MLUKernelSwap\n",tx,gtx);

        float *A = dA + step + step * lda;
        float reg;
        __nram__ float shared_y[N];
        // __nram__ float rA[N];
        __nram__ float temp[MAX_M_SIZE];
        __nram__ float L1[MAX_M_SIZE];
        __nram__ float temp_L1[MAX_M_SIZE];
        __nram__ float tail[MAX_M_SIZE];

        if ( tx<taskDim ) {      
            __memcpy(shared_y,A,n*sizeof(float),LDRAM2NRAM,sizeof(float),lda*sizeof(float),0);     
        }
 

        if (shared_y[0] == 0) {
        (*info) = step + gbstep + 1;
        return;
        }


        int m_per_core=m/taskDim;
        const int m_per_core_=m_per_core;
        int m_=m-m_per_core*(taskDim-1);
        if (tx == taskDim - 1) {
            m_per_core=m_;
        }

        reg=1/shared_y[0];
        
        if(m_per_core-1>=0)
            __memcpy(L1,A+tx*lda*m_per_core_,1*sizeof(float),LDRAM2NRAM,sizeof(float),lda*sizeof(float),m_per_core-1);
            
        int offset_L1=0;
        
         if(tx==0)
        {
            offset_L1++;//指向shared_y的第二个元素
            m_per_core--;
        }
        else if(tx==taskDim-1&&m_per_core_==0) //m=3时 前三个核的m为0，最后一个核需要处理2行，偏移
        {
            offset_L1++;//指向shared_y的第二个元素
            m_per_core--;
        }

        if(m>MAX_M_SIZE)
        {
            int seg=2;
            int num_per_core=m_per_core/seg;
            int rem_num_per_core=m_per_core-seg*num_per_core;
            if(num_per_core>0)
            {
                __bang_mul_scalar(temp_L1+offset_L1,L1+offset_L1,reg,m_per_core);
                for(int j=0;j<seg;j++)
                {

                    for(int i=0;i<n-1;i++)
                    {
                        __memcpy(tail+j*num_per_core, A+tx*lda*m_per_core_+j*num_per_core*lda+offset_L1*lda+i+1,sizeof(float),LDRAM2NRAM,sizeof(float),lda*sizeof(float),num_per_core-1);
                        __bang_cycle_mul(temp+j*num_per_core,temp_L1+offset_L1+j*num_per_core,shared_y+i+1,num_per_core,1);

                        __bang_sub(tail+j*num_per_core,tail+j*num_per_core,temp+j*num_per_core,num_per_core);

                        __memcpy(A+tx*lda*m_per_core_+j*num_per_core*lda+offset_L1*lda+i+1,tail+j*num_per_core,sizeof(float),NRAM2LDRAM,lda*sizeof(float),sizeof(float),num_per_core-1);//写回tail
                    }
                    
                    __memcpy(A+tx*lda*m_per_core_+j*num_per_core*lda+offset_L1*lda,temp_L1+offset_L1+j*num_per_core,sizeof(float),NRAM2LDRAM,lda*sizeof(float),sizeof(float),num_per_core-1);//写回temp_L1   
                }
            }
            if(rem_num_per_core>0)
            {

                for(int i=0;i<n-1;i++)
                {
                    __memcpy(tail+seg*num_per_core,A+tx*lda*m_per_core_+seg*num_per_core*lda+offset_L1*lda+i+1,sizeof(float),LDRAM2NRAM,sizeof(float),lda*sizeof(float),rem_num_per_core-1);
                    __bang_cycle_mul(temp+seg*num_per_core,temp_L1+offset_L1+seg*num_per_core,shared_y+i+1,rem_num_per_core,1);

                    __bang_sub(tail+seg*num_per_core,tail+seg*num_per_core,temp+seg*num_per_core,rem_num_per_core);
                    
                    __memcpy(A+tx*lda*m_per_core_+seg*num_per_core*lda+offset_L1*lda+i+1,tail+seg*num_per_core,sizeof(float),NRAM2LDRAM,lda*sizeof(float),sizeof(float),rem_num_per_core-1);//写回tail
                }
                
                __memcpy(A+tx*lda*m_per_core_+seg*num_per_core*lda+offset_L1*lda,temp_L1+offset_L1+seg*num_per_core,sizeof(float),NRAM2LDRAM,lda*sizeof(float),sizeof(float),rem_num_per_core-1);//写回temp_L1   
                
            }
            
           
            return;
        }
        
        if(m_per_core>0)
        {
            __bang_mul_scalar(temp_L1+offset_L1,L1+offset_L1,reg,m_per_core);
            
            for(int i=0;i<n-1;i++)
            {

                __memcpy(tail,A+tx*lda*m_per_core_+offset_L1*lda+i+1,sizeof(float),LDRAM2NRAM,sizeof(float),lda*sizeof(float),m_per_core-1);
                __bang_cycle_mul(temp,temp_L1+offset_L1,shared_y+i+1,m_per_core,1);

                __bang_sub(tail,tail,temp,m_per_core);

                
                __memcpy(A+tx*lda*m_per_core_+offset_L1*lda+i+1,tail,sizeof(float),NRAM2LDRAM,lda*sizeof(float),sizeof(float),m_per_core-1);//写回tail

            }
            if(m_per_core-1>=0)
                __memcpy(A+tx*lda*m_per_core_+offset_L1*lda,temp_L1+offset_L1,sizeof(float),NRAM2LDRAM,lda*sizeof(float),sizeof(float),m_per_core-1);//写回temp_L1
        }
        
    }





mluOpStatus_t MLUOP_WIN_API KernelScal_ger(cnrtDim3_t k_dim, cnrtFunctionType_t k_type, 
    cnrtQueue_t queue, mluOpDataType_t d_type,
    int m, int n, int step,
    float *dA, int lda,
    int *info, int gbstep)
    {
        
        KERNEL_CHECK(
        MLUKernelScal_ger<<<k_dim, k_type, queue>>>
            (m,n,step,dA,lda,info,gbstep));
        
        return MLUOP_STATUS_SUCCESS;
    }