/*************************************************************************
 * Copyright (C) [2022] by Cambricon, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *************************************************************************/

#include "kernels/kernel.h"
#include "kernels/utils/common.h"
#include "mlu_op_kernel.h"

__nram__ char nram_buffer[MAX_NRAM_SIZE];
#define MIN(x, y) ((x) < (y) ? (x) : (y))
#define BATCH_LIMIT 1
#define INDEX_WEIGHT_LAST_DIM 3
#define INT32_MAX_MASK 0xffffffff
#define INT16_MAX_MASK 0xffff
#define INT32_MASK_REPEAT_TIMES 4
#define INT16_MASK_REPEAT_TIMES 2

template <typename T>
__mlu_func__ void SelectIndicesBetweenMinAndMax(
    int32_t *nram_indices,
    int32_t *nram_indices_transpose,
    float *nram_indices_transpose_addition,
    float *nram_indices_transpose_float,
    float *nram_indices_transpose_float_addition,
    T *nram_weights_transpose,
    const int32_t m_min, const int32_t m_max,
    const int32_t index, const int32_t n_limit,
    const int32_t c_limit, const int32_t m_limit_org) {
  // select the offset between the m_min and m_max
  // convert indices from int32_t to float
  __int322float(nram_indices_transpose_float,
                nram_indices_transpose_float_addition,
                nram_indices_transpose + index * n_limit,
                nram_indices_transpose_addition, n_limit);
  // judge if less than m_max
  __bang_ge_scalar(nram_indices_transpose_float_addition,
                   nram_indices_transpose_float, m_max, n_limit);
  __bang_not(nram_indices_transpose_float_addition,
             nram_indices_transpose_float_addition, n_limit);
  // judge if greater or equal than m_min
  __bang_ge_scalar(nram_indices_transpose_addition,
                   nram_indices_transpose_float, m_min, n_limit);
  // get the bool values in the range of [m_min, m_max)
  __bang_and(nram_indices_transpose_addition,
             nram_indices_transpose_float_addition,
             nram_indices_transpose_addition, n_limit);
#if __BANG_ARCH__ >= 322
  // extra process for the nan/inf
  // set weights to be 0 for the indices not in range of [m_min, m_max)
  if (sizeof(T) == sizeof(float)) {
    int32_t *nram_mask_int32 =
        (int32_t *)nram_indices_transpose_float_addition;
    __bang_float2int32(nram_mask_int32, nram_indices_transpose_addition,
                       n_limit, 0);
    __bang_mul_scalar((int32_t *)nram_mask_int32,
                      (int32_t *)nram_mask_int32,
                      (int32_t)INT32_MAX_MASK, n_limit);
    __bang_band((char *)(nram_weights_transpose + index * n_limit),
                (char *)(nram_weights_transpose + index * n_limit),
                (char *)nram_mask_int32,
                INT32_MASK_REPEAT_TIMES * n_limit);
  } else if (sizeof(T) == sizeof(half)) {
    int16_t *nram_mask_int16 =
        (int16_t *)nram_indices_transpose_float_addition;
    __bang_float2int16_rd(nram_mask_int16,
                          nram_indices_transpose_addition, n_limit, 0);
    __bang_mul_scalar((int16_t *)nram_mask_int16,
                      (int16_t *)nram_mask_int16,
                      (int16_t)INT16_MAX_MASK, n_limit);
    __bang_band((char *)(nram_weights_transpose + index * n_limit),
                (char *)(nram_weights_transpose + index * n_limit),
                (char *)nram_mask_int16,
                INT16_MASK_REPEAT_TIMES * n_limit);
  }
#endif
  // multiply the indices with values in the range of [m_min, m_max)
  __bang_mul(nram_indices_transpose_float, nram_indices_transpose_float,
             nram_indices_transpose_addition, n_limit);
  // get the bool values not in the range of [m_min, m_max)
  __bang_not(nram_indices_transpose_float_addition,
             nram_indices_transpose_addition, n_limit);
  // multiply the values not in the range of [m_min, m_max) with
  // m_limit_org + m_min
  __bang_mul_scalar(nram_indices_transpose_float_addition,
                    nram_indices_transpose_float_addition,
                    m_limit_org + m_min, n_limit);
  // add the indices in range of [m_min, m_max) with the special
  // indices(same as
  // m_limit_org + m_min) not in range of [m_min, m_max)
  __bang_add(nram_indices_transpose_float, nram_indices_transpose_float,
             nram_indices_transpose_float_addition, n_limit);
  // get the relative indices by subtract m_min
  __bang_sub_scalar(nram_indices_transpose_float,
                    nram_indices_transpose_float, m_min, n_limit);
  // get the beginning offset by multiply c_limit
  __bang_mul_scalar(nram_indices_transpose_float,
                    nram_indices_transpose_float, c_limit, n_limit);
  // convert the indices from float type back to int
  __float2int32(nram_indices, nram_indices_transpose_addition,
                nram_indices_transpose_float,
                nram_indices_transpose_float_addition, n_limit);
}

template <typename T>
__mlu_global__ void MLUKernelThreeInterpolateForward(
    const T *features, const int *__restrict__ indices, const T *weights,
    const int b, const int c, const int m, const int n, const int c_limit_size,
    const int m_limit_size, const int n_limit_size, T *output) {
  if (coreId == 0x80) {
    return;
  }
  int32_t align_base_128 = NFU_ALIGN_SIZE / sizeof(T);
  int32_t c_limit = c_limit_size;
  int32_t m_limit = m_limit_size;
  int32_t n_limit = n_limit_size;

  int32_t c_aligned_limit = CEIL_ALIGN(c, c_limit);
  int32_t m_aligned_limit = CEIL_ALIGN(m, m_limit);
  int32_t n_aligned_limit = CEIL_ALIGN(n, n_limit);

  c_limit = c_limit > c_aligned_limit ? c_aligned_limit : c_limit;
  m_limit = m_limit > m_aligned_limit ? m_aligned_limit : m_limit;
  n_limit = n_limit > n_aligned_limit ? n_aligned_limit : n_limit;
  int32_t c_limit_org = c_limit;
  int32_t m_limit_org = m_limit;
  int32_t n_limit_org = n_limit;

  int32_t c_repeated_times = c_aligned_limit / c_limit;
  int32_t m_repeated_times = m_aligned_limit / m_limit;

  int32_t batch_n_repeated_times =
      (b * n_aligned_limit) / (BATCH_LIMIT * n_limit);
  int32_t batch_n_per_core = batch_n_repeated_times / taskDim;
  int32_t batch_n_remain = batch_n_repeated_times % taskDim;

  batch_n_per_core += (taskId < batch_n_remain);

  int32_t features_deal_size = c_limit * m_limit;
  int32_t indices_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  int32_t weights_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  int32_t output_deal_size = c_limit * n_limit;
  int32_t reuse_deal_size = features_deal_size >= output_deal_size
                                ? features_deal_size
                                : output_deal_size;

  /*
   * NRAM partition
   *  |-----------------------------------------------------------------------------------|
   *  |           nram_features                  |        nram_features_transpose         |
   *  |-----------------------------------------------------------------------------------|
   *  |           nram_features_selected         |                    nram_output         |
   *  |-----------------------------------------------------------------------------------|
   *  |      nram_weights         |   nram_weights_transpose  |      nram_indices         |
   *  |-----------------------------------------------------------------------------------|
   *  | nram_indices_transpose(addition/float/float_addition) |
   *  |-----------------------------------------------------------------------------------|
   */

  T *nram_features = (T *)nram_buffer;  // MAX(c_limit*m_limit, c_limit*n_limit)
  T *nram_features_transpose =
      (T *)nram_features + reuse_deal_size;  // m_limit*c_limit
  T *nram_features_selected =
      (T *)nram_features_transpose + features_deal_size;  // n_limit*c_limit
  T *nram_output =
      (T *)nram_features_selected + output_deal_size;     // c_limit*n_limit
  T *nram_weights = (T *)nram_output + output_deal_size;  // n_limit*3
  T *nram_weights_transpose =
      (T *)nram_weights + weights_deal_size;  // n_limit*3
  int32_t *nram_indices =
      (int32_t *)(nram_weights_transpose + weights_deal_size);  // n_limit*3
  int32_t *nram_indices_transpose =
      (int32_t *)nram_indices + indices_deal_size;  // n_limit*3
  float *nram_indices_transpose_addition =
      (float *)(nram_indices_transpose + indices_deal_size);  // n_limit
  float *nram_indices_transpose_float =
      (float *)(nram_indices_transpose_addition + n_limit);  // n_limit
  float *nram_indices_transpose_float_addition =
      (float *)(nram_indices_transpose_float + n_limit);  // n_limit

  for (int32_t i = 0; i < batch_n_per_core; ++i) {
    n_limit = n_limit_org;
    int32_t current_batch_n = i + taskId * batch_n_per_core;
    current_batch_n += (taskId >= batch_n_remain ? batch_n_remain : 0);
    int32_t current_batch = current_batch_n * n_limit / n_aligned_limit;
    int32_t current_n = current_batch_n % (n_aligned_limit / n_limit);

    int32_t real_indices_deal_size = indices_deal_size;
    int32_t actual_n_size = n_limit;

    int32_t n_segment = n_aligned_limit / n_limit;
    int32_t n_remain = n % n_limit;
    if (n_remain == 0) {
      n_remain = n_limit;
    }
    int32_t remains = current_batch_n / n_segment;
    int32_t segments = current_batch_n - remains;

    int32_t *base_addr_indices =
        (int32_t *)indices +
        (segments * n_limit + remains * n_remain) * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_weights =
        (T *)weights +
        (segments * n_limit + remains * n_remain) * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_features = (T *)features + current_batch * c * m;
    T *base_addr_output =
        (T *)output + current_batch * c * n + current_n * n_limit;

    int32_t n_mod_limit = n % n_limit;
    if (current_n == (n_aligned_limit / n_limit - 1) && (n_mod_limit != 0)) {
      real_indices_deal_size = n_mod_limit * INDEX_WEIGHT_LAST_DIM;
      actual_n_size = n_mod_limit;
      n_limit = MIN(CEIL_ALIGN(n_mod_limit, align_base_128), n_limit);
    }
    // 1. Load
    // 1.1 load indices and weights
    __memcpy(nram_indices, base_addr_indices,
             real_indices_deal_size * sizeof(int32_t), GDRAM2NRAM);
    __memcpy(nram_weights, base_addr_weights,
             real_indices_deal_size * sizeof(T), GDRAM2NRAM);

    // transpose the indices and weights
    for (int32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
      __bang_write_value(nram_indices_transpose + index * n_limit, n_limit, -1);
      __bang_write_zero(nram_weights_transpose + index * n_limit, n_limit);
      __memcpy(nram_indices_transpose + index * n_limit, nram_indices + index,
               sizeof(int32_t), NRAM2NRAM, sizeof(int32_t),
               INDEX_WEIGHT_LAST_DIM * sizeof(int32_t), actual_n_size - 1);
      __memcpy(nram_weights_transpose + index * n_limit, nram_weights + index,
               sizeof(T), NRAM2NRAM, sizeof(T),
               INDEX_WEIGHT_LAST_DIM * sizeof(T), actual_n_size - 1);
    }
#if __BANG_ARCH__ >= 322
    // extra process for the nan/inf
    // backup the weights after transpose
    __memcpy(nram_weights, nram_weights_transpose,
             weights_deal_size * sizeof(T), NRAM2NRAM);
#endif

    int32_t c_rem = c;
    for (int32_t j = 0; j < c_repeated_times; ++j) {
      int32_t c_slice = c_limit < c_rem ? c_limit : c_rem;
      c_rem -= c_slice;
      int32_t c_limit_new = c_limit;
      if (c_slice != c_limit && c_slice % c_limit != 0) {
        c_limit_new =
            MIN(CEIL_ALIGN(c_slice % c_limit, align_base_128), c_limit_new);
      }
      // 1.2 load Co*Mo features data
      __bang_write_zero(nram_output, output_deal_size);
      int32_t m_rem = m;
      for (int32_t k = 0; k < m_repeated_times; ++k) {
        int32_t m_slice = m_limit < m_rem ? m_limit : m_rem;
        m_rem -= m_slice;
        int32_t m_limit_new = m_limit;
        if (m_slice != m_limit && m_slice % m_limit != 0) {
          m_limit_new =
              MIN(CEIL_ALIGN(m_slice % m_limit, align_base_128), m_limit_new);
        }
        __memcpy(nram_features,
                 base_addr_features + (j * m * c_limit + k * m_limit),
                 m_slice * sizeof(T), GDRAM2NRAM, m_limit_new * sizeof(T),
                 m * sizeof(T), c_slice - 1);
        // 2. Compute
        __bang_write_zero(nram_features_transpose,
                          features_deal_size + c_limit);
        c_limit = c_limit_new;
        m_limit = m_limit_new;
        // 2.1 transpose features from Co*Mo to Mo*Co to easily select one whole
        // channel data
        __bang_transpose(nram_features_transpose, nram_features, c_limit,
                         m_limit);
        int32_t m_min = k * m_limit_org;
        int32_t m_max = m_min + m_slice;
        for (int32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
          __bang_write_zero(nram_features, output_deal_size);
          __bang_write_zero(nram_features_selected, output_deal_size);
          // 2.2 select the offset between the m_min and m_max
          // convert indices from int32_t to float
          SelectIndicesBetweenMinAndMax(nram_indices, nram_indices_transpose,
                                        nram_indices_transpose_addition,
                                        nram_indices_transpose_float,
                                        nram_indices_transpose_float_addition,
                                        nram_weights_transpose,
                                        m_min, m_max,
                                        index, n_limit,
                                        c_limit, m_limit_org);
          // select the features from m*c to n*c
          // 2.3 select the Mo*Co according to the indices
          for (int32_t s = 0; s < actual_n_size; ++s) {
            // select the features
            __memcpy(nram_features + s * c_limit,
                     nram_features_transpose + nram_indices[s],
                     c_limit * sizeof(T), NRAM2NRAM);
          }  // n_repeated_times
          // 2.4 transpose from No*Co to Co*No to easily do the mul with No
          __bang_transpose(nram_features_selected, nram_features, n_limit,
                           c_limit);
          // 2.5 mul the features and weightss
          __bang_cycle_mul(nram_features_selected, nram_features_selected,
                           nram_weights_transpose + index * n_limit,
                           c_limit * n_limit, n_limit);
          // 2.6 add the different index's results
          __bang_add(nram_output, nram_features_selected, nram_output,
                     c_limit * n_limit);
#if __BANG_ARCH__ >= 322
          // extra process for the nan/inf
          // restore the nram_weights_transpose from nram_weights
          __memcpy(nram_weights_transpose + index * n_limit,
                   nram_weights + index * n_limit, n_limit * sizeof(T),
                   NRAM2NRAM);
#endif
        }  // index
        c_limit = c_limit_org;
        m_limit = m_limit_org;
      }  // m_repeated_time
      // 3. Store Co*No data
      __memcpy(base_addr_output + (j * n * c_limit), nram_output,
               actual_n_size * sizeof(T), NRAM2GDRAM, n * sizeof(T),
               n_limit * sizeof(T), c_slice - 1);
    }  // c_repeated_times
  }    // batch_n_per_core
}

template <typename T>
__mlu_global__ void MLUKernelThreeInterpolateBackward(
    const T *grad_output, const int *__restrict__ indices, const T *weights,
    const int b, const int c, const int m, const int n, const int c_limit_size,
    const int m_limit_size, const int n_limit_size, T *grad_features) {
  if (coreId == 0x80) {
    return;
  }
  int32_t align_base_128 = NFU_ALIGN_SIZE / sizeof(T);
  int32_t c_limit = c_limit_size;
  int32_t m_limit = m_limit_size;
  int32_t n_limit = n_limit_size;

  int32_t c_aligned_limit = CEIL_ALIGN(c, c_limit);
  int32_t m_aligned_limit = CEIL_ALIGN(m, m_limit);
  int32_t n_aligned_limit = CEIL_ALIGN(n, n_limit);

  c_limit = c_limit > c_aligned_limit ? c_aligned_limit : c_limit;
  m_limit = m_limit > m_aligned_limit ? m_aligned_limit : m_limit;
  n_limit = n_limit > n_aligned_limit ? n_aligned_limit : n_limit;
  int32_t c_limit_org = c_limit;
  int32_t m_limit_org = m_limit;
  int32_t n_limit_org = n_limit;

  int32_t c_repeated_times = c_aligned_limit / c_limit;
  int32_t n_repeated_times = n_aligned_limit / n_limit;

  int32_t batch_m_repeated_times =
      (b * m_aligned_limit) / (BATCH_LIMIT * m_limit);
  int32_t batch_m_per_core = batch_m_repeated_times / taskDim;
  int32_t batch_m_remain = batch_m_repeated_times % taskDim;

  batch_m_per_core += (taskId < batch_m_remain);

  int32_t grad_output_deal_size = c_limit * n_limit;
  int32_t indices_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  int32_t weights_deal_size = n_limit * INDEX_WEIGHT_LAST_DIM;
  int32_t grad_features_deal_size = c_limit * m_limit;
  int32_t reuse_deal_size = grad_output_deal_size >= grad_features_deal_size
                                ? grad_output_deal_size
                                : grad_features_deal_size;

  /*
   * NRAM partition
   *  |-------------------------------------------------------------------------------------------|
   *  |           nram_grad_output                  |        nram_grad_output_transpose           |
   *  |-------------------------------------------------------------------------------------------|
   *  |           nram_grad_features                |        nram_grad_features_transpose         |
   *  |-------------------------------------------------------------------------------------------|
   *  |      nram_weights            |   nram_weights_transpose     |      nram_indices           |
   *  |-------------------------------------------------------------------------------------------|
   *  |      nram_indices_transpose(addition/float/float_addition)  |
   *  |-------------------------------------------------------------------------------------------|
   */

  T *nram_grad_output = (T *)nram_buffer;  // c_limit*n_limit
  T *nram_grad_output_transpose =
      (T *)nram_grad_output +
      grad_output_deal_size;  // n_limit*c_limit + c_limit
  T *nram_grad_features = (T *)nram_grad_output_transpose +
                          grad_output_deal_size + c_limit;  // m_limit*c_limit
  T *nram_grad_features_transpose =
      (T *)nram_grad_features +
      grad_features_deal_size;  // max(c_limit*m_limit, c_limit*n_limit)
  T *nram_weights =
      (T *)nram_grad_features_transpose + reuse_deal_size;  // n_limit*3
  T *nram_weights_transpose =
      (T *)nram_weights + weights_deal_size;  // n_limit*3
  int32_t *nram_indices =
      (int32_t *)(nram_weights_transpose + weights_deal_size);  // n_limit*3
  int32_t *nram_indices_transpose =
      (int32_t *)nram_indices + indices_deal_size;  // n_limit*3
  float *nram_indices_transpose_addition =
      (float *)(nram_indices_transpose + indices_deal_size);  // n_limit
  float *nram_indices_transpose_float =
      (float *)(nram_indices_transpose_addition + n_limit);  // n_limit
  float *nram_indices_transpose_float_addition =
      (float *)(nram_indices_transpose_float + n_limit);  // n_limit

  for (int32_t i = 0; i < batch_m_per_core; ++i) {
    m_limit = m_limit_org;
    int32_t current_batch_m = i + taskId * batch_m_per_core;
    current_batch_m += (taskId >= batch_m_remain ? batch_m_remain : 0);
    int32_t current_batch = current_batch_m * m_limit / m_aligned_limit;
    int32_t current_m = current_batch_m % (m_aligned_limit / m_limit);
    int32_t real_indices_deal_size = indices_deal_size;
    int32_t actual_m_size = m_limit;

    int32_t *base_addr_indices =
        (int32_t *)indices + current_batch * n * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_weights =
        (T *)weights + current_batch * n * INDEX_WEIGHT_LAST_DIM;
    T *base_addr_grad_output = (T *)grad_output + current_batch * c * n;
    T *base_addr_grad_features =
        (T *)grad_features +
        /*different batch*/ current_batch * c * m +
        /*different m*/ current_m * m_limit;

    int32_t m_mod_limit = m % m_limit;
    if (current_m == (m_aligned_limit / m_limit - 1) && (m_mod_limit != 0)) {
      actual_m_size = m_mod_limit;
      m_limit = MIN(CEIL_ALIGN(m_mod_limit, align_base_128), m_limit);
    }

    int32_t m_min = current_m * m_limit_org;
    int32_t m_max = m_min + actual_m_size;

    int32_t c_rem = c;
    for (int32_t j = 0; j < c_repeated_times; ++j) {
      int32_t c_slice = c_limit < c_rem ? c_limit : c_rem;
      c_rem -= c_slice;
      int32_t c_limit_new = c_limit;
      if (c_slice != c_limit && c_slice % c_limit != 0) {
        c_limit_new =
            MIN(CEIL_ALIGN(c_slice % c_limit, align_base_128), c_limit_new);
      }
      // initial the nram_grad_features with 0
      __bang_write_zero(nram_grad_features, grad_features_deal_size);
      int32_t n_rem = n;
      for (int32_t k = 0; k < n_repeated_times; ++k) {
        int32_t n_slice = n_limit < n_rem ? n_limit : n_rem;
        n_rem -= n_slice;
        int32_t n_limit_new = n_limit;
        if (n_slice != n_limit && n_slice % n_limit != 0) {
          n_limit_new =
              MIN(CEIL_ALIGN(n_slice % n_limit, align_base_128), n_limit_new);
        }
        real_indices_deal_size = n_slice * INDEX_WEIGHT_LAST_DIM;
        // load weights and indices
        __memcpy(nram_indices,
                 base_addr_indices + k * n_limit * INDEX_WEIGHT_LAST_DIM,
                 real_indices_deal_size * sizeof(int32_t), GDRAM2NRAM);
        __memcpy(nram_weights,
                 base_addr_weights + k * n_limit * INDEX_WEIGHT_LAST_DIM,
                 real_indices_deal_size * sizeof(T), GDRAM2NRAM);
         // load grad_output
        __memcpy(nram_grad_output,
                 base_addr_grad_output + (j * n * c_limit + k * n_limit),
                 n_slice * sizeof(T), GDRAM2NRAM, n_limit_new * sizeof(T),
                 n * sizeof(T), c_slice - 1);
        // transpose the indices and weights
        for (int32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
          __bang_write_value(nram_indices_transpose + index * n_limit, n_limit,
                             -1);
          __bang_write_zero(nram_weights_transpose + index * n_limit, n_limit);
          __memcpy(nram_indices_transpose + index * n_limit_new,
                   nram_indices + index, sizeof(int32_t), NRAM2NRAM,
                   sizeof(int32_t), INDEX_WEIGHT_LAST_DIM * sizeof(int32_t),
                   n_slice - 1);
          __memcpy(nram_weights_transpose + index * n_limit_new,
                   nram_weights + index, sizeof(T), NRAM2NRAM, sizeof(T),
                   INDEX_WEIGHT_LAST_DIM * sizeof(T), n_slice - 1);
        }
#if __BANG_ARCH__ >= 322
        // extra process for the nan/inf
        // backup the weights after transpose
        __memcpy(nram_weights, nram_weights_transpose,
                 weights_deal_size * sizeof(T), NRAM2NRAM);
#endif
        // initial nram_grad_output_transpose with zero
        // and set extra c_limit size that will be selected by the index not in
        // [m_min, m_max)
        __bang_write_zero(nram_grad_output_transpose,
                          grad_output_deal_size + c_limit);
        c_limit = c_limit_new;
        n_limit = n_limit_new;
        for (int32_t index = 0; index < INDEX_WEIGHT_LAST_DIM; ++index) {
          // select the offset between the m_min and m_max
          // convert indices from int32_t to float
          SelectIndicesBetweenMinAndMax(nram_indices, nram_indices_transpose,
                                        nram_indices_transpose_addition,
                                        nram_indices_transpose_float,
                                        nram_indices_transpose_float_addition,
                                        nram_weights_transpose,
                                        m_min, m_max,
                                        index, n_limit,
                                        c_limit, m_limit_org);
          // mul the grad_output and weights
          __bang_cycle_mul(nram_grad_features_transpose, nram_grad_output,
                           nram_weights_transpose + index * n_limit,
                           c_limit * n_limit, n_limit);
          __bang_transpose(nram_grad_output_transpose,
                           nram_grad_features_transpose, c_limit, n_limit);
          // add the mul results to the grad_features selected
          // by the index
          for (int32_t s = 0; s < n_slice; ++s) {
            int selected_index = nram_indices[s];
            __bang_add(nram_grad_features + selected_index,
                       nram_grad_features + selected_index,
                       nram_grad_output_transpose + s * c_limit, c_limit);
          }
#if __BANG_ARCH__ >= 322
          // extra process for the nan/inf
          // restore the nram_weights_transpose from nram_weights
          __memcpy(nram_weights_transpose + index * n_limit,
                   nram_weights + index * n_limit, n_limit * sizeof(T),
                   NRAM2NRAM);
#endif
        }  // index
        c_limit = c_limit_org;
        n_limit = n_limit_org;
      }  // n_repeated_times
      // transpose the results from Mo*Co to Co*Mo
      __bang_transpose(nram_grad_features_transpose, nram_grad_features,
                       m_limit, c_limit_new);
      // store Co*Mo data
      __memcpy(base_addr_grad_features + (j * m * c_limit),
               nram_grad_features_transpose, actual_m_size * sizeof(T),
               NRAM2GDRAM, m * sizeof(T), m_limit * sizeof(T), c_slice - 1);
    }  // c_repeated_times
  }    // batch_m_per_core
}

void MLUOP_WIN_API mluOpUnionKernelThreeInterpolateForwardFloat(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    const void *features, const void *indices, const void *weights, const int b,
    const int c, const int m, const int n, const int c_limit_size,
    const int m_limit_size, const int n_limit_size, void *output) {
  MLUKernelThreeInterpolateForward<<<k_dim, k_type, queue>>>(
      (float *)features, (int *)indices, (float *)weights, b, c, m, n,
      c_limit_size, m_limit_size, n_limit_size, (float *)output);
}

void MLUOP_WIN_API mluOpUnionKernelThreeInterpolateForwardHalf(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    const void *features, const void *indices, const void *weights, const int b,
    const int c, const int m, const int n, const int c_limit_size,
    const int m_limit_size, const int n_limit_size, void *output) {
  MLUKernelThreeInterpolateForward<<<k_dim, k_type, queue>>>(
      (half *)features, (int *)indices, (half *)weights, b, c, m, n,
      c_limit_size, m_limit_size, n_limit_size, (half *)output);
}

void MLUOP_WIN_API mluOpUnionKernelThreeInterpolateBackwardFloat(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    const void *grad_output, const void *indices, const void *weights,
    const int b, const int c, const int m, const int n, const int c_limit_size,
    const int m_limit_size, const int n_limit_size, void *grad_features) {
  MLUKernelThreeInterpolateBackward<<<k_dim, k_type, queue>>>(
      (float *)grad_output, (int *)indices, (float *)weights, b, c, m, n,
      c_limit_size, m_limit_size, n_limit_size, (float *)grad_features);
}

void MLUOP_WIN_API mluOpUnionKernelThreeInterpolateBackwardHalf(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    const void *grad_output, const void *indices, const void *weights,
    const int b, const int c, const int m, const int n, const int c_limit_size,
    const int m_limit_size, const int n_limit_size, void *grad_features) {
  MLUKernelThreeInterpolateBackward<<<k_dim, k_type, queue>>>(
      (half *)grad_output, (int *)indices, (half *)weights, b, c, m, n,
      c_limit_size, m_limit_size, n_limit_size, (half *)grad_features);
}
