# Frac算子开发设计方案

- #### 文档基本信息

| 算子名称    | Frac       |
| ----------- | -------------- |
| 编制人/日期 | 潘健行/2022-6-10 |
| 审批人/日期 |    |

- #### 修改记录

| 修订人 | 修订日期   | 修订描述 |
| ------ | ---------- | -------- |
| 潘健行    | 2022-6-20 | 首次提交 |
| 潘健行    | 2022-8-11 | 第二次提交 |

- #### 内容描述

本文档为 `Frac` 算子的设计文档，包括需求分析、接口设计、方案设计、性能优化记录和方案实施部分。

- #### 算子需求 checklist

* 算子接口描述
* 功能描述
* 框架版本 + 对应源码路径
* 需求对应网络
* 网络中用到的规模
* 是否需要支持原位
* 是否需要支持 stride 机制
* 框架单元测试阈值指标（可选）
## 1. 需求分析
### 1.1 算子需求分析

example:

| 算子功能简介   | 计算输入buffer的小数部分（有符号）           |
| ------------ | ---------------------------------------------|
| 需求来源       | PyTorch                                     |
| 应用网络       | resnet50等                                  |
| 输入数据类型   | float                                 |
| 输入 Shape    | input: [batches, hi, wi, channels]    
| 输入 Layout   | input: NHWC   | 
| 输出数据类型    |float                                 |
| 输出 Shape    | 同输入类型               |
| 输出 Layout   | 同输入类型                             |

### 1.2 算子功能和应用场景描述

功能：计算输入的tensor的每一个元素的分数部分，并返回一个新的tensor，新的tensor中的元素保留原有元素的符号。

例如：输入一个tensor[1, 1.5, -2.0300]，其输出的tensor应该为[0.0, 0.5, -0.03]。

### 1.3 算子输入输出参数要求
| 参数 | 类型（输入/输出） | 支持类型 | 物理布局 | 规模限制
| ------ | ------ | ------ |------ | ------ |
| input | 输入 | float | NHWC | 无 |
| output | 输出 | float | NHWC | 无 |

### 1.4 算子限制
| 限制类型 | 详细说明
| ------ | ------
| 原位限制 | 不支持原位
| stride限制 | 不支持stride机制
| 广播限制 | 不支持广播
|数据类型限制 | 仅支持float

### 1.5 验收标准
#### 1.5.1 精度验收标准
按照精度验收标准的要求明确本算子的精度标准。具体可以参见MLU-OPS精度验收标准.md。

本算子属于复合类算子，验收标准为diff1 <= 3e-3 && diff2 <= 3e-3 。
#### 1.5.2 性能验收标准
具体可以参见MLU-OPS精度验收标准.md。

## 2. 算子接口设计
### 2.1 参考接口
PyTorch接口：
```
torch.frac(input, *, out=None) 
```
### 2.2 接口设计
```
MluOp_frac(input, output, dim0, dim1, dim2, dim3)
```

## 3. 实现方案设计
### 3.1 实现方案
对于输入的tensor的每一个元素，应减去其整数部分，并保留元素原有的符号。
公式为：
$out_i=input_i-\lfloor \vert input_i \vert \rfloor*sgn(input_i)$
### 3.2 伪代码实现


```
import bangpy
from bangpy import tcp

tcp.abs(buffer_abs, buffer_in_n)
tcp.type_convert(buffer_floor, buffer_abs, 0, "tz")
tcp.type_convert(buffer_floor_after, buffer_floor, 0, "tz")
tcp.sign(buffer_sgn, buffer_in_n)
tcp.multiply(buffer_tem, buffer_floor_after, buffer_sgn)
tcp.subtract(buffer_out_n, buffer_in_n, buffer_tem)
```
### 3.3 拆分
把输入的数据按核数量进行拆分。每个核处理自身分到的数据。如果数据相对于总的核数量有余数，那么把这些剩余的数据交给最后一个核来处理，具体实现时通过taskId这一变量实现。

对于每一个核的核内数据处理，应该按照每次捞取最大设置捞取数据量来进行。当总数据量不是每次捞取数据的整数倍时，会有核内数据剩余，此时将所有的剩余数据全部捞取，然后单独计算偏移，在nram中完成计算并放回。
### 3.4 性能优化设计
使用自动流水来进行IO与计算时间的相互掩盖。

使用内存复减少内存开辟和提升内存利用率。

尽量增大每个核单次捞取的最大数据量，以此减少访存的次数。
### 3.5 可维护性设计
1、对每一个函数命名变量命名都有充分的注释。

2、对算子进行模块化设计与拆分，确保模块具有复用性。
### 3.6 测试用例设计
根据需要进行补充。详见算子测试文件。
### 3.7 算子防呆检查
除host端自动生成的部分参数防呆检查外，暂不需要进行其他的防呆检查。
## 4. 算子性能优化记录
### 4.1 当前存在问题的规模说明
无
### 4.2 已经过优化的规格说明
无
