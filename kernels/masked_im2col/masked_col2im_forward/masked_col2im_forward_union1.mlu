/*************************************************************************
 * Copyright (C) [2023] by Cambricon, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *************************************************************************/
#include "masked_col2im_forward.h"

#include <algorithm>

#include "core/logging.h"
#include "kernels/debug.h"
#include "kernels/kernel.h"
#include "kernels/utils/common.h"

__nram__ char data_nram[MAX_NRAM_SIZE];

template <typename T>
__mlu_func__ void MLUMultiKernelMaskedCol2imForward(
    const T *col, const int height, const int width, const int channels,
    const int32_t *mask_h_idx, const int32_t *mask_w_idx, const int mask_cnt,
    T *im) {
  const int channels_max_num_nram = MAX_NRAM_SIZE / sizeof(T);
  if (channels <= channels_max_num_nram) {
    const int deal_num = channels_max_num_nram / channels;
    int mask_per_core = mask_cnt / taskDim;
    const int mask_remain = mask_cnt % taskDim;
    mask_per_core += taskId < mask_remain ? 1 : 0;
    int index_start = taskId < mask_remain
                          ? taskId * mask_per_core
                          : taskId * mask_per_core + mask_remain;
    int loop = mask_per_core / deal_num;
    int remain_num = mask_per_core % deal_num;
    T *nram_col = (T *)data_nram;
    for (int index = 0; index < loop; ++index) {
      int cur_index = index_start + index * deal_num;
      __memcpy(nram_col, col + cur_index * channels,
               deal_num * channels * sizeof(T), GDRAM2NRAM);
      for (int i = 0; i < deal_num; ++i) {
        int mask_index = cur_index + i;
        const int h_im = mask_h_idx[mask_index];
        const int w_im = mask_w_idx[mask_index];
        __memcpy(im + (h_im * width + w_im) * channels, nram_col + i * channels,
                 channels * sizeof(T), NRAM2GDRAM);
      }
    }
    if (remain_num > 0) {
      int cur_index = index_start + loop * deal_num;
      __memcpy(nram_col, col + cur_index * channels,
               remain_num * channels * sizeof(T), GDRAM2NRAM);
      for (int i = 0; i < remain_num; ++i) {
        int mask_index = cur_index + i;
        const int h_im = mask_h_idx[mask_index];
        const int w_im = mask_w_idx[mask_index];
        __memcpy(im + (h_im * width + w_im) * channels, nram_col + i * channels,
                 channels * sizeof(T), NRAM2GDRAM);
      }
    }
  } else {
    for (int index = taskId; index < mask_cnt; index += taskDim) {
      const int m_index = index % mask_cnt;
      const int h_im = mask_h_idx[m_index];
      const int w_im = mask_w_idx[m_index];
      __memcpy(im + (h_im * width + w_im) * channels, col + index * channels,
               channels * sizeof(T), GDRAM2GDRAM);
    }
  }
}

template <typename T>
__mlu_entry__ void MLUUnion1MaskedCol2imForward(
    const void *col, const int height, const int width, const int channels,
    const void *mask_h_idx, const void *mask_w_idx, const int mask_cnt,
    void *im) {
  if (__is_mpu()) {
    return;
  }
  MLUMultiKernelMaskedCol2imForward((T *)col, height, width, channels,
                                    (int32_t *)mask_h_idx,
                                    (int32_t *)mask_w_idx, mask_cnt, (T *)im);
}

mluOpStatus_t MLUOP_WIN_API KernelMaskedCol2imForward(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    const mluOpDataType_t data_dtype, const void *col, const int height,
    const int width, const int channels, const void *mask_h_idx,
    const void *mask_w_idx, const int mask_cnt, void *im) {
  switch (data_dtype) {
    /* Only float and half data types are supported
       in host-side CPP file fool-proof processing. */
    case MLUOP_DTYPE_FLOAT: {
      KERNEL_CHECK(
          MLUUnion1MaskedCol2imForward<float>
          <<<k_dim, k_type, queue>>>(col, height, width, channels, mask_h_idx,
                                     mask_w_idx, mask_cnt, im));
    }; break;
    case MLUOP_DTYPE_HALF: {
      KERNEL_CHECK(MLUUnion1MaskedCol2imForward<half><<<k_dim, k_type, queue>>>(
          col, height, width, channels, mask_h_idx, mask_w_idx, mask_cnt, im));
    }; break;
    default:
      break;
  }
  return MLUOP_STATUS_SUCCESS;
}
