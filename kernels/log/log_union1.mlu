/*************************************************************************
 * Copyright (C) [2022] by Cambricon, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *************************************************************************/
#include "log.h"

#include "core/logging.h"
#include "kernels/debug.h"
#include "kernels/kernel.h"
#include "kernels/unary_op/unary_op_3pipeline.h"
#include "kernels/unary_op/unary_op_5pipeline.h"

#define LOG_LOW_BOUND 1e-8
#define LOG_SCALE 1e12
#define LOG_RECOVER -27.6310211159285482

__nram__ float nram_tmp[NFU_ALIGN_SIZE];
__nram__ char nram_buffer[UNARY_NRAM_SIZE];
#if __BANG_ARCH__ != 520
__mlu_shared__ char sram_buffer[UNARY_SRAM_SIZE];
#endif

template <typename DType_in, typename DType_out>
__mlu_func__ void auxFunc3LogFloat(size_t &output_input_gap,
                                   size_t &ping_pong_gap,
                                   size_t &auxiliary_a_gap,
                                   size_t &auxiliary_b_gap,
                                   size_t &span_num_deal, size_t &align_num,
                                   float coef) {
  align_num = NFU_ALIGN_SIZE / sizeof(DType_in);
  // ping output/input | pong output/input
  span_num_deal = PAD_DOWN(UNARY_NRAM_SIZE / sizeof(DType_in) / 2, align_num);
  output_input_gap = 0;
  ping_pong_gap = span_num_deal * sizeof(DType_in);
  auxiliary_a_gap = 0;
  auxiliary_b_gap = 0;
}

template <typename DType_in, typename DType_out>
__mlu_func__ void computeLogFloat(char *nram_output, char *nram_input,
                                  char *auxiliary_a, char *auxiliary_b,
                                  size_t deal_num, size_t actual_num,
                                  float coef) {
  __bang_log((float *)nram_output, (float *)nram_input, actual_num);
  __bang_mul_scalar((float *)nram_output, (float *)nram_output, (float)coef,
                    deal_num);
}

template <typename DType_in, typename DType_out>
__mlu_func__ void auxFunc3LogHalf(size_t &output_input_gap,
                                  size_t &ping_pong_gap,
                                  size_t &auxiliary_a_gap,
                                  size_t &auxiliary_b_gap,
                                  size_t &span_num_deal, size_t &align_num,
                                  float coef) {
  align_num = NFU_ALIGN_SIZE / sizeof(DType_in);
  // ping output | ping input | pong...
  span_num_deal = PAD_DOWN(UNARY_NRAM_SIZE / sizeof(DType_in) / 4, align_num);
  output_input_gap = span_num_deal * sizeof(DType_in);
  ping_pong_gap = 2 * output_input_gap;
  auxiliary_a_gap = 0;
  auxiliary_b_gap = 0;
}

template <typename DType_in, typename DType_out>
__mlu_func__ void computeLogHalf(char *nram_output, char *nram_input,
                                 char *auxiliary_a, char *auxiliary_b,
                                 size_t deal_num, size_t actual_num,
                                 float coef) {
  __bang_half2float((float *)nram_output, (half *)nram_input, deal_num);
  __bang_log((float *)nram_output, (float *)nram_output, actual_num);
  __bang_mul_scalar((float *)nram_output, (float *)nram_output, coef, deal_num);
  __mluop_float2half((half *)nram_output, (float *)nram_output, deal_num);
}

template <typename DType_in, typename DType_out>
__mlu_func__ void auxFunc5LogFloat(size_t &output_input_gap,
                                   size_t &auxiliary_a_gap,
                                   size_t &auxiliary_b_gap, size_t &num_deal,
                                   size_t &align_num, float coef) {
#if __BANG_ARCH__ != 520  // TODO(sram): tp_520
  int sram_limit = (UNARY_SRAM_SIZE / sizeof(DType_in)) / 8;
  num_deal = (UNARY_NRAM_SIZE / sizeof(DType_in)) / 2;
  num_deal = num_deal < sram_limit ? num_deal : sram_limit;
  num_deal = PAD_DOWN(num_deal, align_num);
  output_input_gap = 0;
#endif
}

template <typename DType_in, typename DType_out>
__mlu_func__ void auxFunc5LogHalf(size_t &output_input_gap,
                                  size_t &auxiliary_a_gap,
                                  size_t &auxiliary_b_gap, size_t &num_deal,
                                  size_t &align_num, float coef) {
#if __BANG_ARCH__ != 520  // TODO(sram): tp_520
  int sram_limit = (UNARY_SRAM_SIZE / sizeof(DType_in)) / 16;
  num_deal = (UNARY_NRAM_SIZE / sizeof(DType_in)) / 4;
  num_deal = num_deal < sram_limit ? num_deal : sram_limit;
  num_deal = PAD_DOWN(num_deal, align_num);
  // x - hf_x
  output_input_gap = num_deal * sizeof(DType_in);
  auxiliary_a_gap = 0;
  auxiliary_b_gap = 0;
#endif
}

// function tion implementation
UNARY_OP_KERNEL_3PIPELINE_IMPLE(Log, Float);
UNARY_OP_KERNEL_3PIPELINE_IMPLE(Log, Half);

UNARY_OP_KERNEL_5PIPELINE_IMPLE(Log, Float);
UNARY_OP_KERNEL_5PIPELINE_IMPLE(Log, Half);

mluOpStatus_t MLUOP_WIN_API Kernel3StagePipelineLog(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    mluOpDataType_t d_type, const mluOpComputationPreference_t prefer,
    const void *x, void *y, size_t num, float coef) {
  // launch kernel
  if (d_type == mluOpDataType_t::MLUOP_DTYPE_FLOAT) {
    KERNEL_CHECK(MLUBlockKernel3StagePipelineLogFloat<float, float>
                 <<<k_dim, k_type, queue>>>((char *)x, (char *)y, num, coef));
  } else {
    // half
    KERNEL_CHECK(MLUBlockKernel3StagePipelineLogHalf<half, half>
                 <<<k_dim, k_type, queue>>>((char *)x, (char *)y, num, coef));
  }
  return MLUOP_STATUS_SUCCESS;
}

mluOpStatus_t MLUOP_WIN_API Kernel5StagePipelineLog(
    cnrtDim3_t k_dim, cnrtFunctionType_t k_type, cnrtQueue_t queue,
    mluOpDataType_t d_type, const mluOpComputationPreference_t prefer,
    const void *x, void *y, size_t num, float coef) {
  // launch kernel
  if (d_type == mluOpDataType_t::MLUOP_DTYPE_FLOAT) {
    KERNEL_CHECK(MLUBlockKernel5StagePipelineLogFloat<float, float>
                 <<<k_dim, k_type, queue>>>((char *)x, (char *)y, num, coef));
  } else {
    KERNEL_CHECK(MLUBlockKernel5StagePipelineLogHalf<half, half>
                 <<<k_dim, k_type, queue>>>((char *)x, (char *)y, num, coef));
  }
  return MLUOP_STATUS_SUCCESS;
}
