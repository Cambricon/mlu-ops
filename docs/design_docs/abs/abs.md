# 1. Abs 算子开发方案设计

* #### 文档基本信息

| 算子名称     | Abs      |
| -----------  | -------   |
| 编制人/日期  | 马向军/2024-05-27 |

* #### 修订记录

| 版本号 | 修订人 | 修订日期 | 修订描述 |
|------- | ----- | ------- | -------- |
| V1.0   | 马向军 | 2024-05-27 | 最初提交 |

* #### 内容描述

本文档为`Abs`算子的设计文档，包括需求分析、接口设计、方案设计、性能优化记录。

- #### 算子需求 checklist

* 算子接口描述
* 功能描述
* 框架版本 + 对应源码路径
* 需求对应网络
* 网络中用到的规模
* 是否需要支持原位
* 是否需要支持 stride 机制
* 框架单元测试阈值指标（可选）

## 1 需求分析

### 1.1 算子需求分析

| 算子功能简介           | 求输入数据的绝对值            |
| ---------------------- | ------------------------------------------- |
| 需求来源               | 无                                     |
| 输入数据类型           | float、half、bfloat16                             |
| 输入Shape              | 任意多维数组 |
| 输入Layout             | ARRAY                                       |
| 输出数据类型           | 同输入                             |
| 输出Shape              | 同输入                              |
| 输出Layout             | 同输入                                       |
| 模式(可选)             | 无                                          |
| 是否需要支持原位       | 否                                          |
| 是否需要支持stride机制 | 是                                          |
| 是否需要支持广播       | 否                                          |


### 1.2 算子功能和应用场景描述
人工智能网络当中Abs是用来计算绝对值函数，在pytorch和tensorflow框架中均有使用。主要用于transformer2网络中，常见的用法是在计算两者误差时取绝对值，还有保证log类似算子输入的非负性
。

本版本(V1.0) 只实现Abs激活算子的基本功能。

Abs的计算公式为：

```math
y_i = |x_i|
```
注：
- i 表示一个多元组的索引, 例如在 4D 时可以表示 (n,c,h,w)
- x_i, y_i 表示多元组中 i 索引处的元素


### 1.3 算子输入输出参数要求
| 参数          | 语义                            | 类型（输入/输出） | 支持类型                | 物理布局 | 规模限制 |
| ------------- | ------------------------------- | ----------------- | ----------------------- | -------- | -------- |
| handle        | MLU-OPS句柄，保存运行上下文信息 | 输入              | mluOpHandle_t           | 无       | 无       |
| x_desc    | 输入参数x的描述信息         | 输入              | mluOpTensorDescriptor_t  | 无       | 无       |
| x    | 指向输入数据x的mlu地址的指针         | 输入              | void* | 无       | 无       |
| y_desc         | 输出参数y的描述信息    | 输出         | mluOpTensorDescriptor_t                   | 无       | 无       |
| y   | 指向输出数据y的mlu地址的指针        | 输出              | void* | 无       | 无       |


### 1.4 算子限制

| 限制类型     | 详细说明                                                     |
| ------------ | ------------------------------------------------------------ |
| 数据类型限制 | 输入输出数据仅支持float/half/bfloat16/int32 |
| 布局限制     | ARRAY                                                        |
| 数据范围限制 | 无 |
| 原位限制     | 不支持原位                                                   |
| stride 限制  | 支持 stride                                           |
| 广播限制     | 不支持广播                                                   |
| shape 限制   | 输入输出向量的shape保持一致                                      |

### 1.5 验收标准
精度验收标准：在相同数据类型的计算下，CPU和MLU计算结果所有数据单点误差的最大值，不得超过1E-7。
性能验收标准：性能IO/计算效率有一项不低于50%。

## 2 算子接口设计

### 2.1 参考接口

#### pytorch
参考pytorch相关接口设计和实现，接口如下：
```c
    torch.abs(const Tensor& x);
```
#### tensorflow
参考tensorflow相关接口设计和实现，接口如下：
```c
    tf.math.abs(x, name=none);
```


### 2.2 接口设计

```c

mluOpStatus_t MLUOP_WIN_API
mluOpAbs(mluOpHandle_t handle,
        const mluOpTensorDescriptor_t x_desc,
        const void *x,
        const mluOpTensorDescriptor_t y_desc,
        void *y);
```

分析：
1. abs目前没有其余参数，输入和输出形状相等。

## 3 实现方案设计

abs算子是element wise类型的算子，因此只需要按照输入数据进行数据切分，目前算子实现了多job并行机制，可按照每个core上可用nram空间对输入数据量进行拆分。

### 3.1 实现方案
- 对输入数据按照数据大小进行拆分，计算每个core处理的数据大小per_core_data。
- 根据每个core的可用nram空间对per_core_data进行拆分，若nram放不下，则循环处理。
- 计算部分调用bang_abs指令实现

分析以上，具体代码可调用三级流水模板实现。

### 3.2 伪代码实现（可选）

### 3.3 拆分（任务拆分，多核拆分）

### 3.4 性能优化设计

调用三级流水模板实现

### 3.5 可维护性设计

bangc代码中加入必要的 log信息，比如输入的规模、数据类型、layout这些，以及如果出错会导致程序core dump的变量，比如IO指令的data_size、dim xyz的值等，这些信息都是有利于快速定位问题。

### 3.6 测试用例设计

- 该算子在网络中用到的规模：
无

### 3.7 算子防呆检查

防呆报错使用错误码： `MLUOP_STATUS_BAD_PARAM`。 

1. 检查handle/x_desc/y_desc/x/y是否为空。
2. 检查x，y数据类型是否相同。
3. 检查x，y的shape是否相同。

## 4 算子性能/精度问题 & 优化记录

### 4.1 当前存在问题的规模说明

（首次提交，暂无） 

### 4.2 已经过优化的规模说明

（首次提交，暂无）